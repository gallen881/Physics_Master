{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "import urllib.parse\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wolframalpha_query(question):\n",
    "    print('Physics Master is using WolframAlpha...', end='\\r')\n",
    "    query = urllib.parse.quote_plus('calculate ' + question)\n",
    "    query_url = f\"http://api.wolframalpha.com/v2/query?\" \\\n",
    "                f\"appid={WOLFRAMALPHA_KEY}\" \\\n",
    "                f\"&input={query}\" \\\n",
    "                f\"&includepodid=Result\" \\\n",
    "                f\"&output=json\"\n",
    "    r = requests.get(query_url)\n",
    "    sys.stdout.write(\"\\033[K\")\n",
    "    if r.status_code == 200:\n",
    "        try:\n",
    "            return r.json()[\"queryresult\"][\"pods\"][0][\"subpods\"][0][\"plaintext\"]\n",
    "        except:\n",
    "            print(question)\n",
    "            print(r.json()[\"queryresult\"])\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def prompt_from_messages(messages):\n",
    "    prompt = ''\n",
    "    for message in messages:\n",
    "        prompt += f\"<|start_header_id|>{message['role']}<|end_header_id|>\\n\\n\"\n",
    "        prompt += f\"{message['content']}<|eot_id|>\"\n",
    "    prompt = prompt[:-10]\n",
    "    return prompt\n",
    "        \n",
    "    \n",
    "with open('config.json') as file:\n",
    "    keys = json.load(file)\n",
    "\n",
    "WOLFRAMALPHA_KEY = keys.get('WOLFRAMALPHA', '')\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id='gallen881/Llama-3-8B-Physics_Master-GGUF',\n",
    "    filename='unsloth.Q4_K_M.gguf',\n",
    "    n_ctx=2048,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content':'You are a professional physics master, you can answer the physics questions you know.' + ' If you are not sure about the answer, especially problems that require calculation or internet, you must use WolframAlpha. To use WolframAlpha, please ONLY output \"<|wolframalpha|>\" in the message, and then ONLY output the calculaion formula you want to use WolframAlpha to calculate. For example, \"<|wolframalpha|>x^2+2x+1=0\" or \"<|wolframalpha|>1024*512/3\", a <|wolframalpha|> tag can ONLY use in a calculation formula, other information is not necessary. <|wolframalpha|x^2+2x+1=0|> is a wrong example. After system get the answer from WolframAlpha, you can continue to answer the question. If you have new question, please output \"<|wolframalpha|>your question here\" again.' if WOLFRAMALPHA_KEY else ''\n",
    "    }\n",
    "]\n",
    "\n",
    "if not WOLFRAMALPHA_KEY:\n",
    "    print('Warning: WolframAlpha API key is not set. You will not be able to use WolframAlpha to answer questions. To set the key, please edit the config.json file.')\n",
    "    print('WolframAlpha disabled.')\n",
    "else:\n",
    "    print('WolframAlpha enabled.')\n",
    "\n",
    "if os.path.exists('chat_history.json'):\n",
    "    with open('chat_history.json', encoding='utf8') as file:\n",
    "        chat_history = json.load(file)\n",
    "else:\n",
    "    chat_history = []\n",
    "\n",
    "chat_time = time.time()\n",
    "chat_history.append({\"time\": chat_time, \"messages\": None})\n",
    "use_wolframalpha = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    if use_wolframalpha:\n",
    "        use_wolframalpha = False\n",
    "        # print('Asking WolframAlpha: ' + query)\n",
    "        query = ''\n",
    "        for i in wolf_answer.split():\n",
    "            print(i, end=' ', flush=True)\n",
    "        response = llm.create_completion(\n",
    "            prompt=prompt_from_messages(messages)\n",
    "        )\n",
    "        print(response['choices'][0]['text'])\n",
    "        messages[-1]['content'] += response['choices'][0]['text']\n",
    "\n",
    "    chat_history[-1]['messages'] = messages\n",
    "    with open('chat_history.json', 'w', encoding='utf8') as file:\n",
    "        json.dump(chat_history, file, indent=4)\n",
    "    user_input = input('\\033[94mYou: \\033[0m')\n",
    "    user_message = {'role': 'user', 'content': user_input}\n",
    "    messages.append(user_message)\n",
    "    print('Physics Master is thinking...', end='\\r')\n",
    "    response = llm.create_chat_completion(\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    # print(response)\n",
    "    sys.stdout.write(\"\\033[K\")\n",
    "    wolf_token = ''\n",
    "    for chunk in response:\n",
    "        delta = chunk['choices'][0]['delta']\n",
    "        if 'role' in delta:\n",
    "            messages.append({'role': delta['role'], 'content': ''})\n",
    "            print(\"\\033[95mPhysics Master: \\033[0m\", end='', flush=True)\n",
    "        elif 'content' in delta:\n",
    "            token = delta['content']\n",
    "            if '<|wolframalpha|>' in wolf_token:\n",
    "                use_wolframalpha = True\n",
    "                query = wolf_token.replace('<|wolframalpha|>', '')\n",
    "                wolf_token = ''\n",
    "\n",
    "            if use_wolframalpha:\n",
    "                if '\\n' in token:\n",
    "                    wolf_answer = wolframalpha_query(query)\n",
    "                    messages[-1]['content'] += wolf_answer\n",
    "                    break\n",
    "                else:\n",
    "                    query += token\n",
    "                continue\n",
    "\n",
    "\n",
    "            wolf_token += token\n",
    "            if wolf_token == '<|wolframalpha|>'[:len(wolf_token)] or '<|wolframalpha|>' in wolf_token:\n",
    "                continue\n",
    "            else:\n",
    "                token = wolf_token\n",
    "                wolf_token = ''\n",
    "\n",
    "            messages[-1]['content'] += token\n",
    "            print(token, end=\"\", flush=True)\n",
    "    print()\n",
    "    if use_wolframalpha and query:\n",
    "        wolf_answer = wolframalpha_query(query)\n",
    "        messages[-1]['content'] += wolf_answer\n",
    "        query = ''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
